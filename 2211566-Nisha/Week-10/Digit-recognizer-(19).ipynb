{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f78732",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:30.625065Z",
     "iopub.status.busy": "2023-05-02T07:20:30.624523Z",
     "iopub.status.idle": "2023-05-02T07:20:30.642450Z",
     "shell.execute_reply": "2023-05-02T07:20:30.641055Z"
    },
    "papermill": {
     "duration": 0.029739,
     "end_time": "2023-05-02T07:20:30.645231",
     "exception": false,
     "start_time": "2023-05-02T07:20:30.615492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682aa66",
   "metadata": {
    "papermill": {
     "duration": 0.005824,
     "end_time": "2023-05-02T07:20:30.657299",
     "exception": false,
     "start_time": "2023-05-02T07:20:30.651475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the introduction to Computer Vision for most people (including me) so I will try to keep it simple. First I will make a baseline model to set as a bench mark, using an ordinary classifier. Then I will make a Convolutional Neural Network model to see how much better it performs than the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed35d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:30.672704Z",
     "iopub.status.busy": "2023-05-02T07:20:30.671369Z",
     "iopub.status.idle": "2023-05-02T07:20:41.187532Z",
     "shell.execute_reply": "2023-05-02T07:20:41.185871Z"
    },
    "papermill": {
     "duration": 10.527095,
     "end_time": "2023-05-02T07:20:41.190822",
     "exception": false,
     "start_time": "2023-05-02T07:20:30.663727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0f2e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:41.207305Z",
     "iopub.status.busy": "2023-05-02T07:20:41.205654Z",
     "iopub.status.idle": "2023-05-02T07:20:47.317415Z",
     "shell.execute_reply": "2023-05-02T07:20:47.316084Z"
    },
    "papermill": {
     "duration": 6.122775,
     "end_time": "2023-05-02T07:20:47.320424",
     "exception": false,
     "start_time": "2023-05-02T07:20:41.197649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce0e3bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:47.334964Z",
     "iopub.status.busy": "2023-05-02T07:20:47.334018Z",
     "iopub.status.idle": "2023-05-02T07:20:47.376015Z",
     "shell.execute_reply": "2023-05-02T07:20:47.374507Z"
    },
    "papermill": {
     "duration": 0.052359,
     "end_time": "2023-05-02T07:20:47.378890",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.326531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3711d5d5",
   "metadata": {
    "papermill": {
     "duration": 0.006033,
     "end_time": "2023-05-02T07:20:47.391399",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.385366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eebcd5",
   "metadata": {
    "papermill": {
     "duration": 0.005984,
     "end_time": "2023-05-02T07:20:47.403756",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.397772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The baseline I will build is the Gradient Boosting algorithm of Tensorflow Decision Forest. This is better than Multi-layer Perceptron which gives an accuracy of 0.95.\n",
    "\n",
    "First, transform the train and test datasets to tf dataset, with the appropriate label for train. Then initialize a Gradient Boosting model wih the first benchmark hyperparameters and fit on the train, predict on the test. The predictions will be as probabilities so convert them to hard predictions. Preprocessing is not required since all features are categorical, there are no missing values and tree based models don't need feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da532f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:47.418616Z",
     "iopub.status.busy": "2023-05-02T07:20:47.418163Z",
     "iopub.status.idle": "2023-05-02T07:20:47.423498Z",
     "shell.execute_reply": "2023-05-02T07:20:47.421925Z"
    },
    "papermill": {
     "duration": 0.016244,
     "end_time": "2023-05-02T07:20:47.426264",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.410020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = tfdf.keras.pd_dataframe_to_tf_dataset(train_data, label='label')\n",
    "# test = tfdf.keras.pd_dataframe_to_tf_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d6d563",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:47.441342Z",
     "iopub.status.busy": "2023-05-02T07:20:47.440848Z",
     "iopub.status.idle": "2023-05-02T07:20:47.446469Z",
     "shell.execute_reply": "2023-05-02T07:20:47.445059Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.01641,
     "end_time": "2023-05-02T07:20:47.449074",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.432664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clf = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")\n",
    "# clf.fit(x=train)\n",
    "# predictions = clf.predict(test)\n",
    "# n_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# score = 0.97046"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35998b",
   "metadata": {
    "papermill": {
     "duration": 0.006007,
     "end_time": "2023-05-02T07:20:47.461638",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.455631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It gives a score of 0.97046 which is a good benchmark. Let's build a CNN and see how much better it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf43be",
   "metadata": {
    "papermill": {
     "duration": 0.007072,
     "end_time": "2023-05-02T07:20:47.475090",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.468018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52812c44",
   "metadata": {
    "papermill": {
     "duration": 0.006017,
     "end_time": "2023-05-02T07:20:47.487428",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.481411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, scale all the features to between 0 and 1 using MinMaxScaler or just dividing by 255 in this case. Scaling affects Neural Networks significantly.\n",
    "\n",
    "Then reshape the data to (-1, 28, 28, 1) because we know they are images with width 28, length 28 and depth 1 pixel. The first parameter -1 is for automatically determining the number of samples in the dataset. One Hot Encode the labels using the to_categorical method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6346d9c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:47.502126Z",
     "iopub.status.busy": "2023-05-02T07:20:47.501706Z",
     "iopub.status.idle": "2023-05-02T07:20:47.625948Z",
     "shell.execute_reply": "2023-05-02T07:20:47.624857Z"
    },
    "papermill": {
     "duration": 0.135001,
     "end_time": "2023-05-02T07:20:47.628734",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.493733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = train_data.drop(['label'], axis=1)\n",
    "y_train = train_data['label']\n",
    "x_test = test_data\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c8c49f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:47.644779Z",
     "iopub.status.busy": "2023-05-02T07:20:47.643614Z",
     "iopub.status.idle": "2023-05-02T07:20:47.657910Z",
     "shell.execute_reply": "2023-05-02T07:20:47.656883Z"
    },
    "papermill": {
     "duration": 0.025184,
     "end_time": "2023-05-02T07:20:47.660505",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.635321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361d2c8",
   "metadata": {
    "papermill": {
     "duration": 0.006289,
     "end_time": "2023-05-02T07:20:47.673571",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.667282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Good news - all classes have roughly the same number of samples so we don't have to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff554c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:47.689573Z",
     "iopub.status.busy": "2023-05-02T07:20:47.688841Z",
     "iopub.status.idle": "2023-05-02T07:20:48.217159Z",
     "shell.execute_reply": "2023-05-02T07:20:48.215890Z"
    },
    "papermill": {
     "duration": 0.540117,
     "end_time": "2023-05-02T07:20:48.220166",
     "exception": false,
     "start_time": "2023-05-02T07:20:47.680049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=scaler.feature_names_in_)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=scaler.feature_names_in_)\n",
    "\n",
    "x_train = x_train.values.reshape(-1,28,28,1)\n",
    "x_test = x_test.values.reshape(-1,28,28,1)\n",
    "y_train = to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068bab88",
   "metadata": {
    "papermill": {
     "duration": 0.006788,
     "end_time": "2023-05-02T07:20:48.233613",
     "exception": false,
     "start_time": "2023-05-02T07:20:48.226825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b31a2",
   "metadata": {
    "papermill": {
     "duration": 0.006907,
     "end_time": "2023-05-02T07:20:48.247360",
     "exception": false,
     "start_time": "2023-05-02T07:20:48.240453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we are ready to build the CNN model. Initialize a sequential model and add layers to it. The model has two components: the feature extraction front end comprised of convolutional and pooling layers, and the classifier backend that will make the prediction.\n",
    "\n",
    "For the feature extraction front end, add convolution layers with increasing number of filters (32, 64, 128) and modest kernel size of (5, 5). Each convolution layer should be followed by batch normalization for standardizing the outputs which results in stabilizing and accelerating the learning process, and a pooling layer. The first convolution layer is the input layer so the input data shape of (28, 28, 1) should be specified for it. The filter maps can then be flattened to provide features to the classifier.\n",
    "\n",
    "For the classifier back end, we know that there are 10 classes so the output layer must have 10 nodes and softmax activation in order to predict the probability distribution of an image belonging to each of the 10 classes. Between the feature extractor and the output layer, we can add a dense layer to interpret the features, in this case with 128 nodes.\n",
    "\n",
    "Using He weight initialization and ReLU activation function in all the layers (except the last output layer) is a good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2861518a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:48.262762Z",
     "iopub.status.busy": "2023-05-02T07:20:48.262145Z",
     "iopub.status.idle": "2023-05-02T07:20:48.649760Z",
     "shell.execute_reply": "2023-05-02T07:20:48.648118Z"
    },
    "papermill": {
     "duration": 0.411169,
     "end_time": "2023-05-02T07:20:48.665205",
     "exception": false,
     "start_time": "2023-05-02T07:20:48.254036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,306\n",
      "Trainable params: 406,602\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), kernel_initializer='he_uniform', padding='Same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), kernel_initializer='he_uniform', padding='Same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(5,5), kernel_initializer='he_uniform', padding='Same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e48ce",
   "metadata": {
    "papermill": {
     "duration": 0.008816,
     "end_time": "2023-05-02T07:20:48.682959",
     "exception": false,
     "start_time": "2023-05-02T07:20:48.674143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before fitting the model on train data, compile it with an appropriate optimizer, loss function and metric. I will use a custom SGD optimizer with momentum 0.9 but you can also use a simple adam optimizer with `optimizer='adam'`. Categorical Crossentropy is a good loss function for this problem since it's a multi class classification. Accuracy is a suitable metric since all classes have roughly the same number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd28974",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-02T07:20:48.704072Z",
     "iopub.status.busy": "2023-05-02T07:20:48.703617Z",
     "iopub.status.idle": "2023-05-02T08:33:29.980292Z",
     "shell.execute_reply": "2023-05-02T08:33:29.978561Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 4361.290788,
     "end_time": "2023-05-02T08:33:29.983358",
     "exception": false,
     "start_time": "2023-05-02T07:20:48.692570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "756/756 - 89s - loss: 0.0980 - accuracy: 0.9703 - val_loss: 0.0438 - val_accuracy: 0.9881 - 89s/epoch - 118ms/step\n",
      "Epoch 2/50\n",
      "756/756 - 88s - loss: 0.0305 - accuracy: 0.9913 - val_loss: 0.0303 - val_accuracy: 0.9905 - 88s/epoch - 117ms/step\n",
      "Epoch 3/50\n",
      "756/756 - 88s - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.0358 - val_accuracy: 0.9888 - 88s/epoch - 117ms/step\n",
      "Epoch 4/50\n",
      "756/756 - 88s - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0303 - val_accuracy: 0.9898 - 88s/epoch - 116ms/step\n",
      "Epoch 5/50\n",
      "756/756 - 87s - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0229 - val_accuracy: 0.9924 - 87s/epoch - 116ms/step\n",
      "Epoch 6/50\n",
      "756/756 - 87s - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0246 - val_accuracy: 0.9919 - 87s/epoch - 115ms/step\n",
      "Epoch 7/50\n",
      "756/756 - 87s - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0233 - val_accuracy: 0.9924 - 87s/epoch - 115ms/step\n",
      "Epoch 8/50\n",
      "756/756 - 86s - loss: 8.4187e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9926 - 86s/epoch - 114ms/step\n",
      "Epoch 9/50\n",
      "756/756 - 86s - loss: 6.9076e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9926 - 86s/epoch - 114ms/step\n",
      "Epoch 10/50\n",
      "756/756 - 86s - loss: 5.9366e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 11/50\n",
      "756/756 - 86s - loss: 5.1265e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9929 - 86s/epoch - 114ms/step\n",
      "Epoch 12/50\n",
      "756/756 - 86s - loss: 4.1809e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9929 - 86s/epoch - 114ms/step\n",
      "Epoch 13/50\n",
      "756/756 - 87s - loss: 3.6452e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9929 - 87s/epoch - 115ms/step\n",
      "Epoch 14/50\n",
      "756/756 - 87s - loss: 3.2058e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9933 - 87s/epoch - 115ms/step\n",
      "Epoch 15/50\n",
      "756/756 - 87s - loss: 3.2496e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9929 - 87s/epoch - 115ms/step\n",
      "Epoch 16/50\n",
      "756/756 - 87s - loss: 2.7248e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9933 - 87s/epoch - 115ms/step\n",
      "Epoch 17/50\n",
      "756/756 - 88s - loss: 2.5291e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9929 - 88s/epoch - 116ms/step\n",
      "Epoch 18/50\n",
      "756/756 - 87s - loss: 2.3761e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9933 - 87s/epoch - 115ms/step\n",
      "Epoch 19/50\n",
      "756/756 - 87s - loss: 2.1799e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9931 - 87s/epoch - 114ms/step\n",
      "Epoch 20/50\n",
      "756/756 - 86s - loss: 2.0177e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 21/50\n",
      "756/756 - 87s - loss: 1.8704e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9931 - 87s/epoch - 114ms/step\n",
      "Epoch 22/50\n",
      "756/756 - 86s - loss: 1.5378e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9933 - 86s/epoch - 113ms/step\n",
      "Epoch 23/50\n",
      "756/756 - 86s - loss: 1.7182e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 24/50\n",
      "756/756 - 86s - loss: 1.5942e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9931 - 86s/epoch - 114ms/step\n",
      "Epoch 25/50\n",
      "756/756 - 86s - loss: 1.4629e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9931 - 86s/epoch - 114ms/step\n",
      "Epoch 26/50\n",
      "756/756 - 86s - loss: 1.4890e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9931 - 86s/epoch - 114ms/step\n",
      "Epoch 27/50\n",
      "756/756 - 86s - loss: 1.5655e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 28/50\n",
      "756/756 - 88s - loss: 1.3745e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9933 - 88s/epoch - 117ms/step\n",
      "Epoch 29/50\n",
      "756/756 - 86s - loss: 1.2959e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 30/50\n",
      "756/756 - 86s - loss: 1.3955e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9931 - 86s/epoch - 113ms/step\n",
      "Epoch 31/50\n",
      "756/756 - 86s - loss: 1.1758e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 32/50\n",
      "756/756 - 86s - loss: 1.2165e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9933 - 86s/epoch - 113ms/step\n",
      "Epoch 33/50\n",
      "756/756 - 84s - loss: 1.1570e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9931 - 84s/epoch - 111ms/step\n",
      "Epoch 34/50\n",
      "756/756 - 84s - loss: 1.0488e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9933 - 84s/epoch - 112ms/step\n",
      "Epoch 35/50\n",
      "756/756 - 86s - loss: 9.5638e-05 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9933 - 86s/epoch - 113ms/step\n",
      "Epoch 36/50\n",
      "756/756 - 86s - loss: 9.5105e-05 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9929 - 86s/epoch - 114ms/step\n",
      "Epoch 37/50\n",
      "756/756 - 86s - loss: 8.8886e-05 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 38/50\n",
      "756/756 - 87s - loss: 9.8258e-05 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9926 - 87s/epoch - 114ms/step\n",
      "Epoch 39/50\n",
      "756/756 - 87s - loss: 9.2557e-05 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9933 - 87s/epoch - 114ms/step\n",
      "Epoch 40/50\n",
      "756/756 - 86s - loss: 9.0463e-05 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9931 - 86s/epoch - 114ms/step\n",
      "Epoch 41/50\n",
      "756/756 - 86s - loss: 8.8622e-05 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9931 - 86s/epoch - 114ms/step\n",
      "Epoch 42/50\n",
      "756/756 - 87s - loss: 9.1523e-05 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9933 - 87s/epoch - 114ms/step\n",
      "Epoch 43/50\n",
      "756/756 - 86s - loss: 8.4798e-05 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9929 - 86s/epoch - 114ms/step\n",
      "Epoch 44/50\n",
      "756/756 - 86s - loss: 8.6843e-05 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 45/50\n",
      "756/756 - 87s - loss: 8.0523e-05 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9931 - 87s/epoch - 114ms/step\n",
      "Epoch 46/50\n",
      "756/756 - 86s - loss: 7.5296e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "Epoch 47/50\n",
      "756/756 - 86s - loss: 7.1675e-05 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9936 - 86s/epoch - 114ms/step\n",
      "Epoch 48/50\n",
      "756/756 - 86s - loss: 7.1125e-05 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9936 - 86s/epoch - 114ms/step\n",
      "Epoch 49/50\n",
      "756/756 - 87s - loss: 7.0983e-05 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9933 - 87s/epoch - 115ms/step\n",
      "Epoch 50/50\n",
      "756/756 - 86s - loss: 6.5515e-05 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9933 - 86s/epoch - 114ms/step\n",
      "875/875 [==============================] - 17s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9,), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.1, batch_size=50, epochs=50, verbose=2)\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "n_predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04847051",
   "metadata": {
    "papermill": {
     "duration": 0.034273,
     "end_time": "2023-05-02T08:33:30.052813",
     "exception": false,
     "start_time": "2023-05-02T08:33:30.018540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f0b97",
   "metadata": {
    "papermill": {
     "duration": 0.03341,
     "end_time": "2023-05-02T08:33:30.119668",
     "exception": false,
     "start_time": "2023-05-02T08:33:30.086258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Observe the sample submission and submit your predictions in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dcd4a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:33:30.191749Z",
     "iopub.status.busy": "2023-05-02T08:33:30.191305Z",
     "iopub.status.idle": "2023-05-02T08:33:30.219651Z",
     "shell.execute_reply": "2023-05-02T08:33:30.218367Z"
    },
    "papermill": {
     "duration": 0.06795,
     "end_time": "2023-05-02T08:33:30.222266",
     "exception": false,
     "start_time": "2023-05-02T08:33:30.154316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      0\n",
       "1            2      0\n",
       "2            3      0\n",
       "3            4      0\n",
       "4            5      0\n",
       "...        ...    ...\n",
       "27995    27996      0\n",
       "27996    27997      0\n",
       "27997    27998      0\n",
       "27998    27999      0\n",
       "27999    28000      0\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffc7ef4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T08:33:30.294878Z",
     "iopub.status.busy": "2023-05-02T08:33:30.293698Z",
     "iopub.status.idle": "2023-05-02T08:33:30.342905Z",
     "shell.execute_reply": "2023-05-02T08:33:30.341627Z"
    },
    "papermill": {
     "duration": 0.088307,
     "end_time": "2023-05-02T08:33:30.345796",
     "exception": false,
     "start_time": "2023-05-02T08:33:30.257489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['ImageId'] = range(1, 28001)\n",
    "df['Label'] = n_predictions\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4395.776923,
   "end_time": "2023-05-02T08:33:33.674865",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-02T07:20:17.897942",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
